{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "surgical-herald",
   "metadata": {},
   "source": [
    "# DnCNN for Image Denoising\n",
    "\n",
    "\n",
    "Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising\n",
    "https://arxiv.org/pdf/1608.03981.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-cardiff",
   "metadata": {},
   "source": [
    "Download and unzip dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "streaming-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "if not Path(\"./small_fastmri_pd_3t\").is_dir():\n",
    "    !gdown --id \"1y78Ad6WwQpMGtxfEZlp97A0iV98kAiJN\"\n",
    "    !unzip -q small_fastmri_pd_3t.zip && rm small_fastmri_pd_3t.zip\n",
    "    \n",
    "if not Path(\"./dncnn-noiseless.pth\").is_file():\n",
    "    !gdown --id \"1azlqmuIkdhcsMQJL_YObF4sEe83D8J8N\" \n",
    "# Noiseless model weights: https://drive.google.com/file/d/1azlqmuIkdhcsMQJL_YObF4sEe83D8J8N/view?usp=sharing\n",
    "# Gaussian model weights: \n",
    "# Salt&Pepper model weights: \n",
    "# Gaussian + Salt&Pepper model weights: \n",
    "\n",
    "# TO DO\n",
    "# 1. Load noiseless and train 10 more epoches with noises, 3 types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sacred-flood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 17 13:19:45 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  On   | 00000000:17:00.0 Off |                  N/A |\n",
      "| 90%   84C    P2   239W / 280W |   9230MiB / 11178MiB |     96%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  On   | 00000000:65:00.0 Off |                  N/A |\n",
      "|  0%   45C    P8    12W / 280W |     12MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  On   | 00000000:66:00.0 Off |                  N/A |\n",
      "|  0%   43C    P8    10W / 280W |     29MiB / 11177MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     13188      C   /home/n_kubrakov/anaconda3/bin/python       3463MiB |\n",
      "|    0     29497      C   /home/e_radionova/anaconda3/bin/python      5755MiB |\n",
      "|    2     26084      G   /usr/lib/xorg/Xorg                             9MiB |\n",
      "|    2     26118      G   /usr/bin/gnome-shell                           6MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "warming-kenya",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs:  3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pylab as plt\n",
    "import torch\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import Callback, ModelCheckpoint\n",
    "from k_space_reconstruction.nets.dncnn import DnCNNModule\n",
    "from k_space_reconstruction.datasets.fastmri import FastMRITransform, FastMRIh5Dataset, RandomMaskFunc\n",
    "from k_space_reconstruction.utils.metrics import pt_msssim, pt_ssim, ssim, nmse, psnr\n",
    "from k_space_reconstruction.utils.loss import l1_loss, compund_mssim_l1_loss\n",
    "from k_space_reconstruction.utils.kspace import spatial2kspace, kspace2spatial\n",
    "\n",
    "print('Available GPUs: ', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-serial",
   "metadata": {},
   "source": [
    "# Dataset initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "manufactured-arcade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekuzmina/dl-bia-project/k_space_reconstruction/datasets/fastmri.py:186: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  self.hf = h5py.File(hf_path)\n"
     ]
    }
   ],
   "source": [
    "transform = FastMRITransform(\n",
    "    RandomMaskFunc([0.08], [4]),\n",
    "    noise_level=1000,\n",
    "    noise_type='none'\n",
    ")\n",
    "\n",
    "train_dataset = FastMRIh5Dataset('small_fastmri_pd_3t/train.h5', transform)\n",
    "val_dataset = FastMRIh5Dataset('small_fastmri_pd_3t/val.h5', transform)\n",
    "train_generator = torch.utils.data.DataLoader(train_dataset, batch_size=1, num_workers=12)\n",
    "val_generator = torch.utils.data.DataLoader(val_dataset, batch_size=1, num_workers=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-arkansas",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "filled-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = DnCNNModule(\n",
    "    dncnn_chans=64, \n",
    "    dncnn_depth=10, \n",
    "    criterion=compund_mssim_l1_loss, \n",
    "    verbose_batch=50, \n",
    "    optimizer='Adam',\n",
    "    lr=1e-4,\n",
    "    lr_step_size=5,\n",
    "    lr_gamma=0.2,\n",
    "    weight_decay=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mobile-component",
   "metadata": {},
   "source": [
    "# Tensorboard logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "noticed-entrance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 8123 (pid 27897), started 1 day, 22:01:47 ago. (Use '!kill 27897' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/ --port 8123"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-darkness",
   "metadata": {},
   "source": [
    "# Init trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "southern-auckland",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    gpus=1, max_epochs=40,\n",
    "    accumulate_grad_batches=32,\n",
    "    terminate_on_nan=True, \n",
    "    default_root_dir='logs/DnCNN',\n",
    "    callbacks=[\n",
    "        pl.callbacks.ModelCheckpoint(\n",
    "            save_last=True,\n",
    "            save_top_k=4, \n",
    "            monitor='val_loss', \n",
    "            filename='{epoch}-{ssim:.4f}-{psnr:.4f}-{nmse:.5f}'\n",
    "        ),\n",
    "        pl.callbacks.LearningRateMonitor(logging_interval='epoch'),\n",
    "        pl.callbacks.GPUStatsMonitor(temperature=True)\n",
    "    ]\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-inside",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "smoking-showcase",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name             | Type                 | Params\n",
      "----------------------------------------------------------\n",
      "0 | net              | DnCNN                | 297 K \n",
      "1 | NMSE             | DistributedMetricSum | 0     \n",
      "2 | SSIM             | DistributedMetricSum | 0     \n",
      "3 | PSNR             | DistributedMetricSum | 0     \n",
      "4 | ValLoss          | DistributedMetricSum | 0     \n",
      "5 | TotExamples      | DistributedMetricSum | 0     \n",
      "6 | TotSliceExamples | DistributedMetricSum | 0     \n",
      "----------------------------------------------------------\n",
      "297 K     Trainable params\n",
      "0         Non-trainable params\n",
      "297 K     Total params\n",
      "1.189     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  10%|▉         | 239/2437 [00:14<02:12, 16.54it/s, loss=0.227, v_num=8, val_loss=0.216]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving latest checkpoint...\n"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "ModelCheckpoint(monitor='ssim') not found in the returned metrics: ['train_loss_step']. HINT: Did you call self.log('ssim', tensor) in the LightningModule?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9e13f2dc67be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0;31m# dispath `start_training` or `start_testing` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_or_test_or_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch38/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch38/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0;31m# hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch38/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mon_train_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;31m# when a checkpoint was saved at the last step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_checkpoint_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshould_update\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch38/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mcheck_checkpoint_callback\u001b[0;34m(self, should_update, is_last)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                 \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_validation_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_early_stopping_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_update\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch38/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\u001b[0m in \u001b[0;36mon_validation_end\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mcheckpoints\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0msaved\u001b[0m \u001b[0mat\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mend\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mval\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \"\"\"\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl_module\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch38/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\u001b[0m in \u001b[0;36msave_checkpoint\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_backward_monitor_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_monitor_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m# track epoch when ckpt was last checked\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch38/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\u001b[0m in \u001b[0;36m_validate_monitor_key\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0;34mf\"HINT: Did you call self.log('{self.monitor}', tensor) in the LightningModule?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m             )\n\u001b[0;32m--> 490\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMisconfigurationException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     def _get_metric_interpolated_filepath_name(\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: ModelCheckpoint(monitor='ssim') not found in the returned metrics: ['train_loss_step']. HINT: Did you call self.log('ssim', tensor) in the LightningModule?"
     ]
    }
   ],
   "source": [
    "trainer.fit(net, train_dataloader=train_generator, val_dataloaders=val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-france",
   "metadata": {},
   "source": [
    "# Test model\n",
    "Load best checkpoint, inference on val dataset and save predictions to .h5 file in logs directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "altered-thing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'epoch=12-ssim=0.7514-psnr=27.9779-nmse=0.01845.ckpt'\r\n",
      "'epoch=13-ssim=0.7516-psnr=27.9857-nmse=0.01842.ckpt'\r\n",
      "'epoch=14-ssim=0.7517-psnr=27.9931-nmse=0.01838.ckpt'\r\n",
      "'epoch=19-ssim=0.7509-psnr=27.9630-nmse=0.01854.ckpt'\r\n",
      " last.ckpt\r\n"
     ]
    }
   ],
   "source": [
    "!ls \"logs/DnCNN/lightning_logs/version_2/checkpoints/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "following-harvey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.net.load_state_dict(torch.load('last.ckpt'))\n",
    "# net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "original-plasma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 395/395 [00:10<00:00, 37.02it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(net, val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "exciting-tower",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-40a733593629>:1: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  hf_pred = h5py.File('logs/DnCNN/2021-05-14 18:49:03.756824.h5')\n",
      "<ipython-input-34-40a733593629>:2: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  hf_gt = h5py.File('small_fastmri_pd_3t/val.h5')\n"
     ]
    }
   ],
   "source": [
    "hf_pred = h5py.File('logs/DnCNN/2021-05-14 18:49:03.756824.h5')\n",
    "hf_gt = h5py.File('small_fastmri_pd_3t/val.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-latter",
   "metadata": {},
   "source": [
    "# Val metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "simplified-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_vals = []\n",
    "nmse_vals = []\n",
    "psnr_vals = []\n",
    "for k in hf_pred.keys():\n",
    "    ks = hf_gt[k][:] * 1e6\n",
    "    gt = np.stack([kspace2spatial(k) for k in ks])\n",
    "    pred = hf_pred[k][:,0]\n",
    "    ssim_vals.append(ssim(gt, pred))\n",
    "    nmse_vals.append(nmse(gt, pred))\n",
    "    psnr_vals.append(psnr(gt, pred))\n",
    "ssim_vals = np.array(ssim_vals)\n",
    "nmse_vals = np.array(nmse_vals)\n",
    "psnr_vals = np.array(psnr_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "technical-grove",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7450819779897695, 0.020334082331490425, 28.62007806339689)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ssim_vals), np.mean(nmse_vals), np.mean(psnr_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-alloy",
   "metadata": {},
   "source": [
    "## Saving Weights of the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "inappropriate-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.net.state_dict(), 'dncnn-noiseless.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-crown",
   "metadata": {},
   "source": [
    "# Continue Training with Noises\n",
    "\n",
    "We take our **noiseless** pre-trained model weight and continue training with different types of noises.\n",
    "\n",
    "- Gaussian noise, lvl: 400\n",
    "- Salt&Pepper noise, lvl: 5e4\n",
    "- Gaussian + Salt&Pepper noise, lvl: 400 + 5e4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-mongolia",
   "metadata": {},
   "source": [
    "### Gaussian Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "noted-germany",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.net.load_state_dict(torch.load('dncnn-noiseless.pth'))\n",
    "# net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "secure-uncle",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = FastMRITransform(\n",
    "    RandomMaskFunc([0.08], [4]),\n",
    "    noise_level=400,\n",
    "    noise_type='normal'\n",
    ")\n",
    "\n",
    "train_dataset = FastMRIh5Dataset('small_fastmri_pd_3t/train.h5', transform)\n",
    "val_dataset = FastMRIh5Dataset('small_fastmri_pd_3t/val.h5', transform)\n",
    "train_generator = torch.utils.data.DataLoader(train_dataset, batch_size=1, num_workers=12)\n",
    "val_generator = torch.utils.data.DataLoader(val_dataset, batch_size=1, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-doubt",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name             | Type                 | Params\n",
      "----------------------------------------------------------\n",
      "0 | net              | DnCNN                | 297 K \n",
      "1 | NMSE             | DistributedMetricSum | 0     \n",
      "2 | SSIM             | DistributedMetricSum | 0     \n",
      "3 | PSNR             | DistributedMetricSum | 0     \n",
      "4 | ValLoss          | DistributedMetricSum | 0     \n",
      "5 | TotExamples      | DistributedMetricSum | 0     \n",
      "6 | TotSliceExamples | DistributedMetricSum | 0     \n",
      "----------------------------------------------------------\n",
      "297 K     Trainable params\n",
      "0         Non-trainable params\n",
      "297 K     Total params\n",
      "1.189     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/2437 [00:00<?, ?it/s]                     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekuzmina/anaconda3/envs/pytorch38/lib/python3.8/site-packages/pytorch_lightning/core/step_result.py:148: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  value = torch.tensor(value, device=device, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  84%|████████▍ | 2042/2437 [05:30<01:04,  6.17it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/395 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▍ | 2045/2437 [05:31<01:03,  6.16it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  84%|████████▍ | 2049/2437 [05:32<01:02,  6.17it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  84%|████████▍ | 2053/2437 [05:32<01:02,  6.18it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  84%|████████▍ | 2057/2437 [05:32<01:01,  6.19it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  85%|████████▍ | 2061/2437 [05:32<01:00,  6.20it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  85%|████████▍ | 2065/2437 [05:32<00:59,  6.21it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  85%|████████▍ | 2069/2437 [05:32<00:59,  6.22it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  85%|████████▌ | 2073/2437 [05:32<00:58,  6.23it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  85%|████████▌ | 2077/2437 [05:33<00:57,  6.24it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  85%|████████▌ | 2081/2437 [05:33<00:56,  6.25it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  86%|████████▌ | 2085/2437 [05:33<00:56,  6.26it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  86%|████████▌ | 2089/2437 [05:33<00:55,  6.27it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  86%|████████▌ | 2093/2437 [05:33<00:54,  6.28it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Validating:  13%|█▎        | 51/395 [00:02<00:16, 21.48it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▌ | 2097/2437 [05:33<00:54,  6.28it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  86%|████████▌ | 2101/2437 [05:33<00:53,  6.29it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  86%|████████▋ | 2105/2437 [05:34<00:52,  6.30it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  87%|████████▋ | 2109/2437 [05:34<00:51,  6.31it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  87%|████████▋ | 2113/2437 [05:34<00:51,  6.32it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  87%|████████▋ | 2117/2437 [05:34<00:50,  6.33it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  87%|████████▋ | 2121/2437 [05:34<00:49,  6.34it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  87%|████████▋ | 2125/2437 [05:34<00:49,  6.35it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Validating:  21%|██        | 83/395 [00:03<00:10, 28.96it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 2129/2437 [05:34<00:48,  6.36it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  88%|████████▊ | 2133/2437 [05:35<00:47,  6.37it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  88%|████████▊ | 2137/2437 [05:35<00:47,  6.37it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Validating:  24%|██▍       | 95/395 [00:04<00:10, 28.77it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 2141/2437 [05:35<00:46,  6.38it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  88%|████████▊ | 2145/2437 [05:35<00:45,  6.39it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  88%|████████▊ | 2149/2437 [05:35<00:45,  6.40it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Validating:  27%|██▋       | 107/395 [00:04<00:13, 22.10it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 2153/2437 [05:35<00:44,  6.41it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  89%|████████▊ | 2157/2437 [05:36<00:43,  6.42it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  89%|████████▊ | 2161/2437 [05:36<00:42,  6.43it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  89%|████████▉ | 2165/2437 [05:36<00:42,  6.44it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  89%|████████▉ | 2169/2437 [05:36<00:41,  6.45it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Validating:  32%|███▏      | 127/395 [00:05<00:09, 29.33it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 2173/2437 [05:36<00:40,  6.45it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  89%|████████▉ | 2177/2437 [05:36<00:40,  6.46it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  89%|████████▉ | 2181/2437 [05:36<00:39,  6.47it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Validating:  35%|███▌      | 139/395 [00:05<00:09, 26.59it/s]\u001b[A\n",
      "Epoch 0:  90%|████████▉ | 2185/2437 [05:37<00:38,  6.48it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  90%|████████▉ | 2189/2437 [05:37<00:38,  6.49it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  90%|████████▉ | 2193/2437 [05:37<00:37,  6.50it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Validating:  38%|███▊      | 151/395 [00:06<00:14, 17.03it/s]\u001b[A\n",
      "Epoch 0:  90%|█████████ | 2197/2437 [05:37<00:36,  6.50it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  90%|█████████ | 2201/2437 [05:37<00:36,  6.51it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  90%|█████████ | 2205/2437 [05:38<00:35,  6.52it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  91%|█████████ | 2209/2437 [05:38<00:34,  6.53it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Validating:  42%|████▏     | 167/395 [00:07<00:08, 26.33it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 2213/2437 [05:38<00:34,  6.54it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  91%|█████████ | 2217/2437 [05:38<00:33,  6.55it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  91%|█████████ | 2221/2437 [05:38<00:32,  6.56it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  91%|█████████▏| 2225/2437 [05:38<00:32,  6.57it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Validating:  46%|████▋     | 183/395 [00:07<00:07, 29.08it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████▏| 2229/2437 [05:38<00:31,  6.58it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  92%|█████████▏| 2233/2437 [05:39<00:30,  6.59it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  92%|█████████▏| 2237/2437 [05:39<00:30,  6.60it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Validating:  49%|████▉     | 195/395 [00:08<00:06, 28.95it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 2241/2437 [05:39<00:29,  6.60it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  92%|█████████▏| 2245/2437 [05:39<00:29,  6.61it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  92%|█████████▏| 2249/2437 [05:39<00:28,  6.62it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  92%|█████████▏| 2253/2437 [05:39<00:27,  6.63it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Validating:  53%|█████▎    | 211/395 [00:08<00:07, 25.05it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 2257/2437 [05:39<00:27,  6.64it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  93%|█████████▎| 2261/2437 [05:40<00:26,  6.65it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  93%|█████████▎| 2265/2437 [05:40<00:25,  6.66it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  93%|█████████▎| 2269/2437 [05:40<00:25,  6.67it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  93%|█████████▎| 2273/2437 [05:40<00:24,  6.68it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  93%|█████████▎| 2277/2437 [05:40<00:23,  6.68it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  94%|█████████▎| 2281/2437 [05:40<00:23,  6.69it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  94%|█████████▍| 2285/2437 [05:40<00:22,  6.70it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  94%|█████████▍| 2289/2437 [05:41<00:22,  6.71it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  94%|█████████▍| 2293/2437 [05:41<00:21,  6.72it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  94%|█████████▍| 2297/2437 [05:41<00:20,  6.73it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  94%|█████████▍| 2301/2437 [05:41<00:20,  6.74it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  95%|█████████▍| 2305/2437 [05:41<00:19,  6.75it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  95%|█████████▍| 2309/2437 [05:41<00:18,  6.75it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Validating:  68%|██████▊   | 267/395 [00:10<00:04, 27.75it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▍| 2313/2437 [05:42<00:18,  6.76it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  95%|█████████▌| 2317/2437 [05:42<00:17,  6.77it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  95%|█████████▌| 2321/2437 [05:42<00:17,  6.78it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  95%|█████████▌| 2325/2437 [05:42<00:16,  6.79it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  96%|█████████▌| 2329/2437 [05:42<00:15,  6.80it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  96%|█████████▌| 2333/2437 [05:42<00:15,  6.81it/s, loss=0.0652, v_num=6, val_loss=0.126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  96%|█████████▌| 2337/2437 [05:42<00:14,  6.82it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Validating:  75%|███████▍  | 295/395 [00:11<00:03, 29.60it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 2341/2437 [05:42<00:14,  6.83it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  96%|█████████▌| 2345/2437 [05:43<00:13,  6.83it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  96%|█████████▋| 2349/2437 [05:43<00:12,  6.84it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  97%|█████████▋| 2353/2437 [05:43<00:12,  6.85it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  97%|█████████▋| 2357/2437 [05:43<00:11,  6.86it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Validating:  80%|███████▉  | 315/395 [00:12<00:03, 25.74it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 2361/2437 [05:43<00:11,  6.87it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  97%|█████████▋| 2365/2437 [05:44<00:10,  6.87it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  97%|█████████▋| 2369/2437 [05:44<00:09,  6.88it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  97%|█████████▋| 2373/2437 [05:44<00:09,  6.89it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Validating:  84%|████████▍ | 331/395 [00:13<00:02, 28.68it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 2377/2437 [05:44<00:08,  6.90it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  98%|█████████▊| 2381/2437 [05:44<00:08,  6.91it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  98%|█████████▊| 2385/2437 [05:44<00:07,  6.92it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  98%|█████████▊| 2389/2437 [05:44<00:06,  6.93it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  98%|█████████▊| 2393/2437 [05:44<00:06,  6.94it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  98%|█████████▊| 2397/2437 [05:45<00:05,  6.94it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  99%|█████████▊| 2401/2437 [05:45<00:05,  6.95it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  99%|█████████▊| 2405/2437 [05:45<00:04,  6.96it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  99%|█████████▉| 2409/2437 [05:45<00:04,  6.97it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  99%|█████████▉| 2413/2437 [05:45<00:03,  6.98it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  99%|█████████▉| 2417/2437 [05:45<00:02,  6.99it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0:  99%|█████████▉| 2421/2437 [05:46<00:02,  7.00it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0: 100%|█████████▉| 2425/2437 [05:46<00:01,  7.01it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0: 100%|█████████▉| 2429/2437 [05:46<00:01,  7.01it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0: 100%|█████████▉| 2433/2437 [05:46<00:00,  7.02it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0: 100%|██████████| 2437/2437 [05:46<00:00,  7.03it/s, loss=0.0652, v_num=6, val_loss=0.126]\n",
      "Epoch 0: 100%|██████████| 2437/2437 [05:46<00:00,  7.03it/s, loss=0.0652, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  84%|████████▍ | 2042/2437 [04:37<00:53,  7.36it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/395 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 2044/2437 [04:38<00:53,  7.34it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  84%|████████▍ | 2048/2437 [04:38<00:52,  7.35it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  84%|████████▍ | 2052/2437 [04:38<00:52,  7.36it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  84%|████████▍ | 2056/2437 [04:38<00:51,  7.37it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Validating:   4%|▎         | 14/395 [00:01<00:20, 18.25it/s]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 2060/2437 [04:38<00:51,  7.38it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  85%|████████▍ | 2064/2437 [04:39<00:50,  7.40it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  85%|████████▍ | 2068/2437 [04:39<00:49,  7.41it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  85%|████████▌ | 2072/2437 [04:39<00:49,  7.42it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Validating:   8%|▊         | 30/395 [00:01<00:14, 25.98it/s]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 2076/2437 [04:39<00:48,  7.43it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  85%|████████▌ | 2080/2437 [04:39<00:47,  7.44it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  86%|████████▌ | 2084/2437 [04:39<00:47,  7.45it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  86%|████████▌ | 2088/2437 [04:39<00:46,  7.46it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Validating:  12%|█▏        | 46/395 [00:02<00:12, 28.02it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 2092/2437 [04:40<00:46,  7.47it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  86%|████████▌ | 2096/2437 [04:40<00:45,  7.47it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  86%|████████▌ | 2100/2437 [04:40<00:45,  7.48it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Validating:  15%|█▍        | 58/395 [00:02<00:15, 21.13it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 2104/2437 [04:40<00:44,  7.49it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  86%|████████▋ | 2108/2437 [04:40<00:43,  7.51it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  87%|████████▋ | 2112/2437 [04:40<00:43,  7.52it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  87%|████████▋ | 2116/2437 [04:41<00:42,  7.53it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Validating:  19%|█▊        | 74/395 [00:03<00:11, 27.33it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 2120/2437 [04:41<00:42,  7.54it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  87%|████████▋ | 2124/2437 [04:41<00:41,  7.55it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  87%|████████▋ | 2128/2437 [04:41<00:40,  7.56it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  87%|████████▋ | 2132/2437 [04:41<00:40,  7.57it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Validating:  23%|██▎       | 90/395 [00:04<00:10, 28.73it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2136/2437 [04:41<00:39,  7.58it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  88%|████████▊ | 2140/2437 [04:41<00:39,  7.59it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  88%|████████▊ | 2144/2437 [04:42<00:38,  7.59it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Validating:  26%|██▌       | 102/395 [00:04<00:16, 17.80it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 2148/2437 [04:42<00:38,  7.60it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  88%|████████▊ | 2152/2437 [04:42<00:37,  7.61it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  88%|████████▊ | 2156/2437 [04:42<00:36,  7.62it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Validating:  29%|██▉       | 114/395 [00:05<00:11, 23.88it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 2160/2437 [04:42<00:36,  7.63it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  89%|████████▉ | 2164/2437 [04:43<00:35,  7.64it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  89%|████████▉ | 2168/2437 [04:43<00:35,  7.66it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Validating:  32%|███▏      | 126/395 [00:05<00:09, 27.24it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 2172/2437 [04:43<00:34,  7.67it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  89%|████████▉ | 2176/2437 [04:43<00:34,  7.68it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  89%|████████▉ | 2180/2437 [04:43<00:33,  7.69it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Validating:  35%|███▍      | 138/395 [00:05<00:09, 27.86it/s]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 2184/2437 [04:43<00:32,  7.70it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  90%|████████▉ | 2188/2437 [04:43<00:32,  7.71it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  90%|████████▉ | 2192/2437 [04:44<00:31,  7.72it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  90%|█████████ | 2196/2437 [04:44<00:31,  7.72it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Validating:  39%|███▉      | 154/395 [00:06<00:10, 22.13it/s]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 2200/2437 [04:44<00:30,  7.73it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  90%|█████████ | 2204/2437 [04:44<00:30,  7.74it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  91%|█████████ | 2208/2437 [04:44<00:29,  7.75it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  91%|█████████ | 2212/2437 [04:44<00:28,  7.76it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Validating:  43%|████▎     | 170/395 [00:07<00:08, 26.94it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 2216/2437 [04:45<00:28,  7.77it/s, loss=0.0467, v_num=6, val_loss=0.101]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  91%|█████████ | 2220/2437 [04:45<00:27,  7.78it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  91%|█████████▏| 2224/2437 [04:45<00:27,  7.79it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Validating:  46%|████▌     | 182/395 [00:07<00:08, 26.46it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 2228/2437 [04:45<00:26,  7.80it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  92%|█████████▏| 2232/2437 [04:45<00:26,  7.81it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  92%|█████████▏| 2236/2437 [04:45<00:25,  7.82it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Validating:  49%|████▉     | 194/395 [00:08<00:07, 28.00it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2240/2437 [04:45<00:25,  7.83it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  92%|█████████▏| 2244/2437 [04:46<00:24,  7.84it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  92%|█████████▏| 2248/2437 [04:46<00:24,  7.85it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Validating:  52%|█████▏    | 206/395 [00:08<00:08, 22.30it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 2252/2437 [04:46<00:23,  7.86it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  93%|█████████▎| 2256/2437 [04:46<00:22,  7.87it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  93%|█████████▎| 2260/2437 [04:46<00:22,  7.88it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Validating:  55%|█████▌    | 218/395 [00:09<00:06, 26.89it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 2264/2437 [04:46<00:21,  7.89it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  93%|█████████▎| 2268/2437 [04:47<00:21,  7.90it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  93%|█████████▎| 2272/2437 [04:47<00:20,  7.91it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  93%|█████████▎| 2276/2437 [04:47<00:20,  7.92it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Validating:  59%|█████▉    | 234/395 [00:09<00:05, 29.17it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 2280/2437 [04:47<00:19,  7.93it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  94%|█████████▎| 2284/2437 [04:47<00:19,  7.94it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  94%|█████████▍| 2288/2437 [04:47<00:18,  7.95it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Validating:  62%|██████▏   | 246/395 [00:10<00:05, 28.82it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2292/2437 [04:47<00:18,  7.96it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  94%|█████████▍| 2296/2437 [04:48<00:17,  7.97it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  94%|█████████▍| 2300/2437 [04:48<00:17,  7.98it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Validating:  65%|██████▌   | 258/395 [00:10<00:05, 22.86it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 2304/2437 [04:48<00:16,  7.99it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  95%|█████████▍| 2308/2437 [04:48<00:16,  8.00it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  95%|█████████▍| 2312/2437 [04:48<00:15,  8.01it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Validating:  68%|██████▊   | 270/395 [00:11<00:04, 27.06it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 2316/2437 [04:48<00:15,  8.02it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  95%|█████████▌| 2320/2437 [04:49<00:14,  8.03it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  95%|█████████▌| 2324/2437 [04:49<00:14,  8.04it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Validating:  71%|███████▏  | 282/395 [00:11<00:04, 27.88it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2328/2437 [04:49<00:13,  8.05it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  96%|█████████▌| 2332/2437 [04:49<00:13,  8.06it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  96%|█████████▌| 2336/2437 [04:49<00:12,  8.07it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Validating:  74%|███████▍  | 294/395 [00:11<00:03, 27.75it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 2340/2437 [04:49<00:12,  8.08it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  96%|█████████▌| 2344/2437 [04:50<00:11,  8.08it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  96%|█████████▋| 2348/2437 [04:50<00:11,  8.09it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Validating:  77%|███████▋  | 306/395 [00:12<00:04, 20.22it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2352/2437 [04:50<00:10,  8.10it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  97%|█████████▋| 2356/2437 [04:50<00:09,  8.11it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  97%|█████████▋| 2360/2437 [04:50<00:09,  8.12it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Validating:  81%|████████  | 318/395 [00:13<00:03, 24.98it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 2364/2437 [04:50<00:08,  8.13it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  97%|█████████▋| 2368/2437 [04:50<00:08,  8.14it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  97%|█████████▋| 2372/2437 [04:51<00:07,  8.15it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  97%|█████████▋| 2376/2437 [04:51<00:07,  8.16it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Validating:  85%|████████▍ | 334/395 [00:13<00:02, 28.41it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2380/2437 [04:51<00:06,  8.17it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  98%|█████████▊| 2384/2437 [04:51<00:06,  8.18it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  98%|█████████▊| 2388/2437 [04:51<00:05,  8.19it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  98%|█████████▊| 2392/2437 [04:51<00:05,  8.20it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Validating:  89%|████████▊ | 350/395 [00:14<00:01, 29.20it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 2396/2437 [04:52<00:04,  8.20it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  98%|█████████▊| 2400/2437 [04:52<00:04,  8.21it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  99%|█████████▊| 2404/2437 [04:52<00:04,  8.22it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  99%|█████████▉| 2408/2437 [04:52<00:03,  8.23it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  99%|█████████▉| 2412/2437 [04:52<00:03,  8.24it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  99%|█████████▉| 2416/2437 [04:52<00:02,  8.25it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  99%|█████████▉| 2420/2437 [04:52<00:02,  8.26it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1:  99%|█████████▉| 2424/2437 [04:53<00:01,  8.27it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1: 100%|█████████▉| 2428/2437 [04:53<00:01,  8.28it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1: 100%|█████████▉| 2432/2437 [04:53<00:00,  8.29it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1: 100%|█████████▉| 2436/2437 [04:53<00:00,  8.30it/s, loss=0.0467, v_num=6, val_loss=0.101]\n",
      "Epoch 1: 100%|██████████| 2437/2437 [04:53<00:00,  8.30it/s, loss=0.0467, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  84%|████████▍ | 2042/2437 [06:01<01:10,  5.64it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/395 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 2044/2437 [06:02<01:09,  5.63it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  84%|████████▍ | 2048/2437 [06:02<01:08,  5.64it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  84%|████████▍ | 2052/2437 [06:03<01:08,  5.65it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  84%|████████▍ | 2056/2437 [06:03<01:07,  5.66it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  85%|████████▍ | 2060/2437 [06:03<01:06,  5.67it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  85%|████████▍ | 2064/2437 [06:03<01:05,  5.68it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Validating:   6%|▌         | 22/395 [00:01<00:15, 24.10it/s]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 2068/2437 [06:03<01:04,  5.69it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  85%|████████▌ | 2072/2437 [06:03<01:04,  5.70it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  85%|████████▌ | 2076/2437 [06:03<01:03,  5.70it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  85%|████████▌ | 2080/2437 [06:04<01:02,  5.71it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Validating:  10%|▉         | 38/395 [00:02<00:12, 28.41it/s]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 2084/2437 [06:04<01:01,  5.72it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  86%|████████▌ | 2088/2437 [06:04<01:00,  5.73it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  86%|████████▌ | 2092/2437 [06:04<01:00,  5.74it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Validating:  13%|█▎        | 50/395 [00:02<00:12, 28.68it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  86%|████████▌ | 2096/2437 [06:04<00:59,  5.75it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  86%|████████▌ | 2100/2437 [06:04<00:58,  5.75it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  86%|████████▋ | 2104/2437 [06:05<00:57,  5.76it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  86%|████████▋ | 2108/2437 [06:05<00:56,  5.77it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Validating:  17%|█▋        | 66/395 [00:03<00:12, 25.74it/s]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2112/2437 [06:05<00:56,  5.78it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  87%|████████▋ | 2116/2437 [06:05<00:55,  5.79it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  87%|████████▋ | 2120/2437 [06:05<00:54,  5.80it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Validating:  20%|█▉        | 78/395 [00:03<00:11, 28.22it/s]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 2124/2437 [06:05<00:53,  5.81it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  87%|████████▋ | 2128/2437 [06:05<00:53,  5.82it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  87%|████████▋ | 2132/2437 [06:06<00:52,  5.82it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  88%|████████▊ | 2136/2437 [06:06<00:51,  5.83it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  88%|████████▊ | 2140/2437 [06:06<00:50,  5.84it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Validating:  25%|██▍       | 98/395 [00:04<00:10, 28.71it/s]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2144/2437 [06:06<00:50,  5.85it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  88%|████████▊ | 2148/2437 [06:06<00:49,  5.86it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  88%|████████▊ | 2152/2437 [06:06<00:48,  5.86it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Validating:  28%|██▊       | 110/395 [00:04<00:12, 23.67it/s]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 2156/2437 [06:07<00:47,  5.87it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  89%|████████▊ | 2160/2437 [06:07<00:47,  5.88it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  89%|████████▉ | 2164/2437 [06:07<00:46,  5.89it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  89%|████████▉ | 2168/2437 [06:07<00:45,  5.90it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  89%|████████▉ | 2172/2437 [06:07<00:44,  5.91it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Validating:  33%|███▎      | 130/395 [00:05<00:09, 28.24it/s]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 2176/2437 [06:07<00:44,  5.92it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  89%|████████▉ | 2180/2437 [06:07<00:43,  5.92it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  90%|████████▉ | 2184/2437 [06:08<00:42,  5.93it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  90%|████████▉ | 2188/2437 [06:08<00:41,  5.94it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  90%|████████▉ | 2192/2437 [06:08<00:41,  5.95it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Validating:  38%|███▊      | 150/395 [00:06<00:08, 28.88it/s]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 2196/2437 [06:08<00:40,  5.96it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  90%|█████████ | 2200/2437 [06:08<00:39,  5.96it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  90%|█████████ | 2204/2437 [06:08<00:39,  5.97it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  91%|█████████ | 2208/2437 [06:09<00:38,  5.98it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Validating:  42%|████▏     | 166/395 [00:07<00:08, 26.10it/s]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 2212/2437 [06:09<00:37,  5.99it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  91%|█████████ | 2216/2437 [06:09<00:36,  6.00it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  91%|█████████ | 2220/2437 [06:09<00:36,  6.01it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  91%|█████████▏| 2224/2437 [06:09<00:35,  6.02it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  91%|█████████▏| 2228/2437 [06:09<00:34,  6.03it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  92%|█████████▏| 2232/2437 [06:09<00:33,  6.03it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Validating:  48%|████▊     | 190/395 [00:07<00:07, 29.10it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2236/2437 [06:10<00:33,  6.04it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  92%|█████████▏| 2240/2437 [06:10<00:32,  6.05it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  92%|█████████▏| 2244/2437 [06:10<00:31,  6.06it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Validating:  51%|█████     | 202/395 [00:08<00:09, 20.85it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 2248/2437 [06:10<00:31,  6.07it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  92%|█████████▏| 2252/2437 [06:10<00:30,  6.07it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  93%|█████████▎| 2256/2437 [06:10<00:29,  6.08it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  93%|█████████▎| 2260/2437 [06:11<00:29,  6.09it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Validating:  55%|█████▌    | 218/395 [00:08<00:06, 27.25it/s]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2264/2437 [06:11<00:28,  6.10it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  93%|█████████▎| 2268/2437 [06:11<00:27,  6.11it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  93%|█████████▎| 2272/2437 [06:11<00:26,  6.12it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Validating:  58%|█████▊    | 230/395 [00:09<00:05, 28.41it/s]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 2276/2437 [06:11<00:26,  6.13it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  94%|█████████▎| 2280/2437 [06:11<00:25,  6.13it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  94%|█████████▎| 2284/2437 [06:11<00:24,  6.14it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  94%|█████████▍| 2288/2437 [06:12<00:24,  6.15it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Validating:  62%|██████▏   | 246/395 [00:09<00:05, 28.30it/s]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2292/2437 [06:12<00:23,  6.16it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  94%|█████████▍| 2296/2437 [06:12<00:22,  6.16it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  94%|█████████▍| 2300/2437 [06:12<00:22,  6.17it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  95%|█████████▍| 2304/2437 [06:12<00:21,  6.18it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Validating:  66%|██████▋   | 262/395 [00:10<00:05, 25.04it/s]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 2308/2437 [06:12<00:20,  6.19it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  95%|█████████▍| 2312/2437 [06:13<00:20,  6.20it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  95%|█████████▌| 2316/2437 [06:13<00:19,  6.21it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Validating:  69%|██████▉   | 274/395 [00:11<00:04, 27.82it/s]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 2320/2437 [06:13<00:18,  6.22it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  95%|█████████▌| 2324/2437 [06:13<00:18,  6.22it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  96%|█████████▌| 2328/2437 [06:13<00:17,  6.23it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  96%|█████████▌| 2332/2437 [06:13<00:16,  6.24it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Validating:  73%|███████▎  | 290/395 [00:11<00:03, 29.00it/s]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 2336/2437 [06:13<00:16,  6.25it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  96%|█████████▌| 2340/2437 [06:13<00:15,  6.26it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  96%|█████████▌| 2344/2437 [06:14<00:14,  6.26it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Validating:  76%|███████▋  | 302/395 [00:12<00:04, 19.21it/s]\u001b[A\n",
      "Epoch 2:  96%|█████████▋| 2348/2437 [06:14<00:14,  6.27it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  97%|█████████▋| 2352/2437 [06:14<00:13,  6.28it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  97%|█████████▋| 2356/2437 [06:14<00:12,  6.29it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  97%|█████████▋| 2360/2437 [06:14<00:12,  6.30it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  97%|█████████▋| 2364/2437 [06:14<00:11,  6.30it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Validating:  82%|████████▏ | 322/395 [00:12<00:02, 27.51it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 2368/2437 [06:15<00:10,  6.31it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  97%|█████████▋| 2372/2437 [06:15<00:10,  6.32it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  97%|█████████▋| 2376/2437 [06:15<00:09,  6.33it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Validating:  85%|████████▍ | 334/395 [00:13<00:02, 28.32it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 2380/2437 [06:15<00:08,  6.34it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  98%|█████████▊| 2384/2437 [06:15<00:08,  6.35it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  98%|█████████▊| 2388/2437 [06:15<00:07,  6.35it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  98%|█████████▊| 2392/2437 [06:15<00:07,  6.36it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  98%|█████████▊| 2396/2437 [06:16<00:06,  6.37it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  98%|█████████▊| 2400/2437 [06:16<00:05,  6.38it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Validating:  91%|█████████ | 358/395 [00:14<00:01, 23.41it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▊| 2404/2437 [06:16<00:05,  6.38it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  99%|█████████▉| 2408/2437 [06:16<00:04,  6.39it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  99%|█████████▉| 2412/2437 [06:16<00:03,  6.40it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  99%|█████████▉| 2416/2437 [06:16<00:03,  6.41it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Validating:  95%|█████████▍| 374/395 [00:14<00:00, 27.86it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 2420/2437 [06:17<00:02,  6.42it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2:  99%|█████████▉| 2424/2437 [06:17<00:02,  6.43it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2: 100%|█████████▉| 2428/2437 [06:17<00:01,  6.43it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2: 100%|█████████▉| 2432/2437 [06:17<00:00,  6.44it/s, loss=0.0431, v_num=6, val_loss=0.0881]\n",
      "Epoch 2: 100%|██████████| 2437/2437 [06:17<00:00,  6.45it/s, loss=0.0431, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  84%|████████▍ | 2042/2437 [05:45<01:06,  5.90it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/395 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 2044/2437 [05:46<01:06,  5.89it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  84%|████████▍ | 2048/2437 [05:46<01:05,  5.90it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  84%|████████▍ | 2052/2437 [05:47<01:05,  5.91it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  84%|████████▍ | 2056/2437 [05:47<01:04,  5.92it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  85%|████████▍ | 2060/2437 [05:47<01:03,  5.93it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  85%|████████▍ | 2064/2437 [05:47<01:02,  5.94it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Validating:   6%|▌         | 22/395 [00:01<00:15, 24.29it/s]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 2068/2437 [05:47<01:02,  5.95it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  85%|████████▌ | 2072/2437 [05:47<01:01,  5.96it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  85%|████████▌ | 2076/2437 [05:47<01:00,  5.97it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Validating:   9%|▊         | 34/395 [00:01<00:13, 27.51it/s]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 2080/2437 [05:48<00:59,  5.98it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  86%|████████▌ | 2084/2437 [05:48<00:58,  5.99it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  86%|████████▌ | 2088/2437 [05:48<00:58,  5.99it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  86%|████████▌ | 2092/2437 [05:48<00:57,  6.00it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Validating:  13%|█▎        | 50/395 [00:02<00:11, 29.23it/s]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 2096/2437 [05:48<00:56,  6.01it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  86%|████████▌ | 2100/2437 [05:48<00:55,  6.02it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  86%|████████▋ | 2104/2437 [05:49<00:55,  6.03it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  86%|████████▋ | 2108/2437 [05:49<00:54,  6.04it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Validating:  17%|█▋        | 66/395 [00:03<00:12, 26.03it/s]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2112/2437 [05:49<00:53,  6.05it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  87%|████████▋ | 2116/2437 [05:49<00:53,  6.06it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  87%|████████▋ | 2120/2437 [05:49<00:52,  6.06it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Validating:  20%|█▉        | 78/395 [00:03<00:11, 27.78it/s]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 2124/2437 [05:49<00:51,  6.07it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  87%|████████▋ | 2128/2437 [05:49<00:50,  6.08it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  87%|████████▋ | 2132/2437 [05:49<00:50,  6.09it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  88%|████████▊ | 2136/2437 [05:50<00:49,  6.10it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  88%|████████▊ | 2140/2437 [05:50<00:48,  6.11it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  88%|████████▊ | 2144/2437 [05:50<00:47,  6.12it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  88%|████████▊ | 2148/2437 [05:50<00:47,  6.13it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  88%|████████▊ | 2152/2437 [05:50<00:46,  6.13it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Validating:  28%|██▊       | 110/395 [00:04<00:11, 23.80it/s]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 2156/2437 [05:50<00:45,  6.14it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  89%|████████▊ | 2160/2437 [05:51<00:45,  6.15it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  89%|████████▉ | 2164/2437 [05:51<00:44,  6.16it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  89%|████████▉ | 2168/2437 [05:51<00:43,  6.17it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  89%|████████▉ | 2172/2437 [05:51<00:42,  6.18it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  89%|████████▉ | 2176/2437 [05:51<00:42,  6.19it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  89%|████████▉ | 2180/2437 [05:51<00:41,  6.20it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Validating:  35%|███▍      | 138/395 [00:05<00:09, 27.22it/s]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 2184/2437 [05:51<00:40,  6.21it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  90%|████████▉ | 2188/2437 [05:52<00:40,  6.21it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  90%|████████▉ | 2192/2437 [05:52<00:39,  6.22it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  90%|█████████ | 2196/2437 [05:52<00:38,  6.23it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Validating:  39%|███▉      | 154/395 [00:06<00:11, 20.62it/s]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 2200/2437 [05:52<00:37,  6.24it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  90%|█████████ | 2204/2437 [05:52<00:37,  6.25it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  91%|█████████ | 2208/2437 [05:52<00:36,  6.26it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Validating:  42%|████▏     | 166/395 [00:07<00:08, 26.09it/s]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 2212/2437 [05:53<00:35,  6.26it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  91%|█████████ | 2216/2437 [05:53<00:35,  6.27it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  91%|█████████ | 2220/2437 [05:53<00:34,  6.28it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  91%|█████████▏| 2224/2437 [05:53<00:33,  6.29it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  91%|█████████▏| 2228/2437 [05:53<00:33,  6.30it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Validating:  47%|████▋     | 186/395 [00:07<00:07, 27.76it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2232/2437 [05:53<00:32,  6.31it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  92%|█████████▏| 2236/2437 [05:53<00:31,  6.32it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  92%|█████████▏| 2240/2437 [05:54<00:31,  6.33it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Validating:  50%|█████     | 198/395 [00:08<00:06, 28.22it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 2244/2437 [05:54<00:30,  6.33it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  92%|█████████▏| 2248/2437 [05:54<00:29,  6.34it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  92%|█████████▏| 2252/2437 [05:54<00:29,  6.35it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  93%|█████████▎| 2256/2437 [05:54<00:28,  6.36it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  93%|█████████▎| 2260/2437 [05:54<00:27,  6.37it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  93%|█████████▎| 2264/2437 [05:55<00:27,  6.38it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  93%|█████████▎| 2268/2437 [05:55<00:26,  6.39it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  93%|█████████▎| 2272/2437 [05:55<00:25,  6.39it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  93%|█████████▎| 2276/2437 [05:55<00:25,  6.40it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  94%|█████████▎| 2280/2437 [05:55<00:24,  6.41it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  94%|█████████▎| 2284/2437 [05:55<00:23,  6.42it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  94%|█████████▍| 2288/2437 [05:55<00:23,  6.43it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  94%|█████████▍| 2292/2437 [05:56<00:22,  6.44it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Validating:  63%|██████▎   | 250/395 [00:10<00:04, 29.63it/s]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2296/2437 [05:56<00:21,  6.44it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  94%|█████████▍| 2300/2437 [05:56<00:21,  6.45it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  95%|█████████▍| 2304/2437 [05:56<00:20,  6.46it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  95%|█████████▍| 2308/2437 [05:56<00:19,  6.47it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  95%|█████████▍| 2312/2437 [05:56<00:19,  6.48it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  95%|█████████▌| 2316/2437 [05:56<00:18,  6.49it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  95%|█████████▌| 2320/2437 [05:57<00:18,  6.50it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Validating:  70%|███████   | 278/395 [00:11<00:04, 28.99it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 2324/2437 [05:57<00:17,  6.51it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  96%|█████████▌| 2328/2437 [05:57<00:16,  6.51it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  96%|█████████▌| 2332/2437 [05:57<00:16,  6.52it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  96%|█████████▌| 2336/2437 [05:57<00:15,  6.53it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  96%|█████████▌| 2340/2437 [05:57<00:14,  6.54it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Validating:  75%|███████▌  | 298/395 [00:11<00:03, 28.14it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 2344/2437 [05:58<00:14,  6.55it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  96%|█████████▋| 2348/2437 [05:58<00:13,  6.55it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  97%|█████████▋| 2352/2437 [05:58<00:12,  6.56it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  97%|█████████▋| 2356/2437 [05:58<00:12,  6.57it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  97%|█████████▋| 2360/2437 [05:58<00:11,  6.58it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  97%|█████████▋| 2364/2437 [05:58<00:11,  6.59it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  97%|█████████▋| 2368/2437 [05:58<00:10,  6.60it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  97%|█████████▋| 2372/2437 [05:59<00:09,  6.61it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  97%|█████████▋| 2376/2437 [05:59<00:09,  6.62it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  98%|█████████▊| 2380/2437 [05:59<00:08,  6.62it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  98%|█████████▊| 2384/2437 [05:59<00:07,  6.63it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  98%|█████████▊| 2388/2437 [05:59<00:07,  6.64it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  98%|█████████▊| 2392/2437 [05:59<00:06,  6.65it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  98%|█████████▊| 2396/2437 [06:00<00:06,  6.65it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  98%|█████████▊| 2400/2437 [06:00<00:05,  6.66it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  99%|█████████▊| 2404/2437 [06:00<00:04,  6.67it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  99%|█████████▉| 2408/2437 [06:00<00:04,  6.68it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  99%|█████████▉| 2412/2437 [06:00<00:03,  6.69it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  99%|█████████▉| 2416/2437 [06:00<00:03,  6.70it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  99%|█████████▉| 2420/2437 [06:00<00:02,  6.71it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3:  99%|█████████▉| 2424/2437 [06:00<00:01,  6.72it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3: 100%|█████████▉| 2428/2437 [06:01<00:01,  6.72it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3: 100%|█████████▉| 2432/2437 [06:01<00:00,  6.73it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3: 100%|█████████▉| 2436/2437 [06:01<00:00,  6.74it/s, loss=0.0417, v_num=6, val_loss=0.0849]\n",
      "Epoch 3: 100%|██████████| 2437/2437 [06:01<00:00,  6.74it/s, loss=0.0417, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  84%|████████▍ | 2042/2437 [04:01<00:46,  8.46it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/395 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 2044/2437 [04:02<00:46,  8.43it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  84%|████████▍ | 2049/2437 [04:02<00:45,  8.45it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  84%|████████▍ | 2054/2437 [04:02<00:45,  8.47it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  84%|████████▍ | 2059/2437 [04:02<00:44,  8.48it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  85%|████████▍ | 2064/2437 [04:02<00:43,  8.50it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  85%|████████▍ | 2069/2437 [04:02<00:43,  8.52it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  85%|████████▌ | 2074/2437 [04:03<00:42,  8.53it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  85%|████████▌ | 2079/2437 [04:03<00:41,  8.55it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  86%|████████▌ | 2084/2437 [04:03<00:41,  8.57it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  86%|████████▌ | 2089/2437 [04:03<00:40,  8.58it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  86%|████████▌ | 2094/2437 [04:03<00:39,  8.59it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  86%|████████▌ | 2099/2437 [04:03<00:39,  8.61it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  86%|████████▋ | 2104/2437 [04:03<00:38,  8.62it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  87%|████████▋ | 2109/2437 [04:04<00:37,  8.64it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  87%|████████▋ | 2114/2437 [04:04<00:37,  8.66it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  87%|████████▋ | 2119/2437 [04:04<00:36,  8.67it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  87%|████████▋ | 2124/2437 [04:04<00:36,  8.69it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  87%|████████▋ | 2129/2437 [04:04<00:35,  8.70it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  88%|████████▊ | 2134/2437 [04:04<00:34,  8.72it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  88%|████████▊ | 2139/2437 [04:04<00:34,  8.74it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  88%|████████▊ | 2144/2437 [04:05<00:33,  8.74it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  88%|████████▊ | 2149/2437 [04:05<00:32,  8.76it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  88%|████████▊ | 2154/2437 [04:05<00:32,  8.78it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  89%|████████▊ | 2159/2437 [04:05<00:31,  8.79it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  89%|████████▉ | 2164/2437 [04:05<00:30,  8.81it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  89%|████████▉ | 2169/2437 [04:05<00:30,  8.82it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  89%|████████▉ | 2174/2437 [04:05<00:29,  8.84it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  89%|████████▉ | 2179/2437 [04:06<00:29,  8.86it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  90%|████████▉ | 2184/2437 [04:06<00:28,  8.87it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  90%|████████▉ | 2189/2437 [04:06<00:27,  8.89it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Validating:  37%|███▋      | 147/395 [00:04<00:06, 38.86it/s]\u001b[A\n",
      "Epoch 4:  90%|█████████ | 2194/2437 [04:06<00:27,  8.90it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  90%|█████████ | 2199/2437 [04:06<00:26,  8.91it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  90%|█████████ | 2204/2437 [04:06<00:26,  8.93it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  91%|█████████ | 2209/2437 [04:06<00:25,  8.94it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  91%|█████████ | 2214/2437 [04:07<00:24,  8.96it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  91%|█████████ | 2219/2437 [04:07<00:24,  8.98it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  91%|█████████▏| 2224/2437 [04:07<00:23,  8.99it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  91%|█████████▏| 2229/2437 [04:07<00:23,  9.01it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  92%|█████████▏| 2234/2437 [04:07<00:22,  9.02it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  92%|█████████▏| 2239/2437 [04:07<00:21,  9.04it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  92%|█████████▏| 2244/2437 [04:07<00:21,  9.05it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  92%|█████████▏| 2249/2437 [04:08<00:20,  9.07it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  92%|█████████▏| 2254/2437 [04:08<00:20,  9.08it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Validating:  54%|█████▎    | 212/395 [00:06<00:05, 33.63it/s]\u001b[A\n",
      "Epoch 4:  93%|█████████▎| 2259/2437 [04:08<00:19,  9.10it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  93%|█████████▎| 2264/2437 [04:08<00:18,  9.11it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  93%|█████████▎| 2269/2437 [04:08<00:18,  9.13it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  93%|█████████▎| 2274/2437 [04:08<00:17,  9.14it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  94%|█████████▎| 2279/2437 [04:08<00:17,  9.16it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  94%|█████████▎| 2284/2437 [04:08<00:16,  9.17it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  94%|█████████▍| 2289/2437 [04:09<00:16,  9.19it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  94%|█████████▍| 2294/2437 [04:09<00:15,  9.20it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  94%|█████████▍| 2299/2437 [04:09<00:14,  9.21it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  95%|█████████▍| 2304/2437 [04:09<00:14,  9.23it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  95%|█████████▍| 2309/2437 [04:09<00:13,  9.25it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  95%|█████████▍| 2314/2437 [04:09<00:13,  9.26it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  95%|█████████▌| 2319/2437 [04:09<00:12,  9.28it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  95%|█████████▌| 2324/2437 [04:10<00:12,  9.29it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  96%|█████████▌| 2329/2437 [04:10<00:11,  9.31it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  96%|█████████▌| 2334/2437 [04:10<00:11,  9.32it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  96%|█████████▌| 2339/2437 [04:10<00:10,  9.34it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  96%|█████████▌| 2344/2437 [04:10<00:09,  9.35it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  96%|█████████▋| 2349/2437 [04:10<00:09,  9.36it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  97%|█████████▋| 2354/2437 [04:11<00:08,  9.38it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  97%|█████████▋| 2359/2437 [04:11<00:08,  9.39it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  97%|█████████▋| 2364/2437 [04:11<00:07,  9.41it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Validating:  82%|████████▏ | 322/395 [00:09<00:02, 34.52it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 2369/2437 [04:11<00:07,  9.42it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  97%|█████████▋| 2374/2437 [04:11<00:06,  9.44it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  98%|█████████▊| 2379/2437 [04:11<00:06,  9.45it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  98%|█████████▊| 2384/2437 [04:11<00:05,  9.47it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  98%|█████████▊| 2389/2437 [04:11<00:05,  9.48it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  98%|█████████▊| 2394/2437 [04:12<00:04,  9.49it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  98%|█████████▊| 2399/2437 [04:12<00:03,  9.51it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  99%|█████████▊| 2404/2437 [04:12<00:03,  9.52it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  99%|█████████▉| 2409/2437 [04:12<00:02,  9.54it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  99%|█████████▉| 2414/2437 [04:12<00:02,  9.55it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  99%|█████████▉| 2419/2437 [04:12<00:01,  9.57it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4:  99%|█████████▉| 2424/2437 [04:12<00:01,  9.58it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4: 100%|█████████▉| 2429/2437 [04:13<00:00,  9.60it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4: 100%|█████████▉| 2434/2437 [04:13<00:00,  9.61it/s, loss=0.0408, v_num=6, val_loss=0.0825]\n",
      "Epoch 4: 100%|██████████| 2437/2437 [04:13<00:00,  9.62it/s, loss=0.0408, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  84%|████████▍ | 2042/2437 [04:33<00:52,  7.48it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/395 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  84%|████████▍ | 2045/2437 [04:34<00:52,  7.46it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  84%|████████▍ | 2050/2437 [04:34<00:51,  7.47it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:   2%|▏         | 8/395 [00:01<00:33, 11.39it/s]\u001b[A\n",
      "Epoch 5:  84%|████████▍ | 2055/2437 [04:34<00:51,  7.49it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  85%|████████▍ | 2060/2437 [04:34<00:50,  7.50it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:   5%|▍         | 18/395 [00:01<00:17, 21.35it/s]\u001b[A\n",
      "Epoch 5:  85%|████████▍ | 2065/2437 [04:34<00:49,  7.51it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:   6%|▌         | 24/395 [00:01<00:15, 24.68it/s]\u001b[A\n",
      "Epoch 5:  85%|████████▍ | 2070/2437 [04:34<00:48,  7.53it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  85%|████████▌ | 2075/2437 [04:35<00:48,  7.54it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:   8%|▊         | 33/395 [00:01<00:13, 26.76it/s]\u001b[A\n",
      "Epoch 5:  85%|████████▌ | 2080/2437 [04:35<00:47,  7.55it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  86%|████████▌ | 2085/2437 [04:35<00:46,  7.57it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  86%|████████▌ | 2090/2437 [04:35<00:45,  7.58it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  86%|████████▌ | 2095/2437 [04:36<00:45,  7.59it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  13%|█▎        | 53/395 [00:02<00:17, 20.06it/s]\u001b[A\n",
      "Epoch 5:  86%|████████▌ | 2100/2437 [04:36<00:44,  7.60it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  86%|████████▋ | 2105/2437 [04:36<00:43,  7.62it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  16%|█▌        | 63/395 [00:03<00:13, 25.38it/s]\u001b[A\n",
      "Epoch 5:  87%|████████▋ | 2110/2437 [04:36<00:42,  7.63it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  17%|█▋        | 69/395 [00:03<00:12, 27.03it/s]\u001b[A\n",
      "Epoch 5:  87%|████████▋ | 2115/2437 [04:36<00:42,  7.64it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  87%|████████▋ | 2120/2437 [04:36<00:41,  7.66it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  20%|█▉        | 78/395 [00:03<00:11, 28.28it/s]\u001b[A\n",
      "Epoch 5:  87%|████████▋ | 2125/2437 [04:37<00:40,  7.67it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  87%|████████▋ | 2130/2437 [04:37<00:39,  7.68it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  22%|██▏       | 88/395 [00:03<00:10, 29.10it/s]\u001b[A\n",
      "Epoch 5:  88%|████████▊ | 2135/2437 [04:37<00:39,  7.70it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  88%|████████▊ | 2140/2437 [04:37<00:38,  7.71it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  25%|██▍       | 98/395 [00:04<00:10, 29.32it/s]\u001b[A\n",
      "Epoch 5:  88%|████████▊ | 2145/2437 [04:37<00:37,  7.72it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  26%|██▋       | 104/395 [00:04<00:13, 21.01it/s]\u001b[A\n",
      "Epoch 5:  88%|████████▊ | 2150/2437 [04:38<00:37,  7.73it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  88%|████████▊ | 2155/2437 [04:38<00:36,  7.74it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  89%|████████▊ | 2160/2437 [04:38<00:35,  7.76it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  30%|██▉       | 118/395 [00:05<00:10, 26.89it/s]\u001b[A\n",
      "Epoch 5:  89%|████████▉ | 2165/2437 [04:38<00:35,  7.77it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  89%|████████▉ | 2170/2437 [04:38<00:34,  7.78it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  32%|███▏      | 128/395 [00:05<00:09, 28.68it/s]\u001b[A\n",
      "Epoch 5:  89%|████████▉ | 2175/2437 [04:38<00:33,  7.80it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  34%|███▍      | 134/395 [00:05<00:09, 28.36it/s]\u001b[A\n",
      "Epoch 5:  89%|████████▉ | 2180/2437 [04:39<00:32,  7.81it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  90%|████████▉ | 2185/2437 [04:39<00:32,  7.82it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  36%|███▌      | 143/395 [00:06<00:08, 28.35it/s]\u001b[A\n",
      "Epoch 5:  90%|████████▉ | 2190/2437 [04:39<00:31,  7.84it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  38%|███▊      | 149/395 [00:06<00:08, 28.45it/s]\u001b[A\n",
      "Epoch 5:  90%|█████████ | 2195/2437 [04:39<00:30,  7.84it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  90%|█████████ | 2200/2437 [04:40<00:30,  7.86it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  40%|████      | 158/395 [00:06<00:10, 22.41it/s]\u001b[A\n",
      "Epoch 5:  90%|█████████ | 2205/2437 [04:40<00:29,  7.87it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  42%|████▏     | 164/395 [00:06<00:09, 25.06it/s]\u001b[A\n",
      "Epoch 5:  91%|█████████ | 2210/2437 [04:40<00:28,  7.88it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  91%|█████████ | 2215/2437 [04:40<00:28,  7.90it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  44%|████▍     | 173/395 [00:07<00:08, 27.45it/s]\u001b[A\n",
      "Epoch 5:  91%|█████████ | 2220/2437 [04:40<00:27,  7.91it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  45%|████▌     | 179/395 [00:07<00:07, 28.32it/s]\u001b[A\n",
      "Epoch 5:  91%|█████████▏| 2225/2437 [04:40<00:26,  7.92it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  92%|█████████▏| 2230/2437 [04:41<00:26,  7.93it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  48%|████▊     | 188/395 [00:07<00:07, 27.89it/s]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 2235/2437 [04:41<00:25,  7.95it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  92%|█████████▏| 2240/2437 [04:41<00:24,  7.96it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  50%|█████     | 198/395 [00:08<00:06, 28.62it/s]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 2245/2437 [04:41<00:24,  7.97it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  52%|█████▏    | 204/395 [00:08<00:08, 22.73it/s]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 2250/2437 [04:41<00:23,  7.98it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  93%|█████████▎| 2255/2437 [04:42<00:22,  7.99it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  93%|█████████▎| 2260/2437 [04:42<00:22,  8.01it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  55%|█████▌    | 218/395 [00:08<00:06, 27.52it/s]\u001b[A\n",
      "Epoch 5:  93%|█████████▎| 2265/2437 [04:42<00:21,  8.02it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  57%|█████▋    | 224/395 [00:09<00:06, 28.41it/s]\u001b[A\n",
      "Epoch 5:  93%|█████████▎| 2270/2437 [04:42<00:20,  8.03it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  93%|█████████▎| 2275/2437 [04:42<00:20,  8.05it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  59%|█████▉    | 233/395 [00:09<00:05, 28.36it/s]\u001b[A\n",
      "Epoch 5:  94%|█████████▎| 2280/2437 [04:42<00:19,  8.06it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  61%|██████    | 239/395 [00:09<00:05, 28.42it/s]\u001b[A\n",
      "Epoch 5:  94%|█████████▍| 2285/2437 [04:43<00:18,  8.07it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  94%|█████████▍| 2290/2437 [04:43<00:18,  8.08it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  63%|██████▎   | 248/395 [00:10<00:05, 28.48it/s]\u001b[A\n",
      "Epoch 5:  94%|█████████▍| 2295/2437 [04:43<00:17,  8.09it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  64%|██████▍   | 254/395 [00:10<00:06, 21.72it/s]\u001b[A\n",
      "Epoch 5:  94%|█████████▍| 2300/2437 [04:43<00:16,  8.10it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  95%|█████████▍| 2305/2437 [04:43<00:16,  8.12it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  67%|██████▋   | 263/395 [00:10<00:05, 26.01it/s]\u001b[A\n",
      "Epoch 5:  95%|█████████▍| 2310/2437 [04:44<00:15,  8.13it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  68%|██████▊   | 269/395 [00:10<00:04, 27.48it/s]\u001b[A\n",
      "Epoch 5:  95%|█████████▍| 2315/2437 [04:44<00:14,  8.14it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  95%|█████████▌| 2320/2437 [04:44<00:14,  8.16it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  95%|█████████▌| 2325/2437 [04:44<00:13,  8.17it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  72%|███████▏  | 283/395 [00:11<00:03, 29.47it/s]\u001b[A\n",
      "Epoch 5:  96%|█████████▌| 2330/2437 [04:44<00:13,  8.18it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  96%|█████████▌| 2335/2437 [04:44<00:12,  8.19it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  74%|███████▍  | 293/395 [00:11<00:03, 29.49it/s]\u001b[A\n",
      "Epoch 5:  96%|█████████▌| 2340/2437 [04:45<00:11,  8.21it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  76%|███████▌  | 299/395 [00:11<00:03, 29.03it/s]\u001b[A\n",
      "Epoch 5:  96%|█████████▌| 2345/2437 [04:45<00:11,  8.21it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  96%|█████████▋| 2350/2437 [04:45<00:10,  8.23it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  78%|███████▊  | 308/395 [00:12<00:03, 23.00it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 2355/2437 [04:45<00:09,  8.24it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  79%|███████▉  | 314/395 [00:12<00:03, 25.59it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 2360/2437 [04:46<00:09,  8.25it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  97%|█████████▋| 2365/2437 [04:46<00:08,  8.26it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  82%|████████▏ | 323/395 [00:12<00:02, 27.23it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 2370/2437 [04:46<00:08,  8.28it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  83%|████████▎ | 329/395 [00:13<00:02, 27.28it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 2375/2437 [04:46<00:07,  8.29it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  98%|█████████▊| 2380/2437 [04:46<00:06,  8.30it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  86%|████████▌ | 338/395 [00:13<00:02, 27.61it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 2385/2437 [04:46<00:06,  8.31it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  98%|█████████▊| 2390/2437 [04:47<00:05,  8.32it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  88%|████████▊ | 349/395 [00:13<00:01, 28.56it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 2395/2437 [04:47<00:05,  8.33it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  98%|█████████▊| 2400/2437 [04:47<00:04,  8.34it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  91%|█████████ | 359/395 [00:14<00:01, 23.30it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▊| 2405/2437 [04:47<00:03,  8.36it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  99%|█████████▉| 2410/2437 [04:48<00:03,  8.37it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  93%|█████████▎| 368/395 [00:14<00:01, 26.20it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 2415/2437 [04:48<00:02,  8.38it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5:  99%|█████████▉| 2420/2437 [04:48<00:02,  8.39it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  96%|█████████▌| 378/395 [00:15<00:00, 28.06it/s]\u001b[A\n",
      "Epoch 5: 100%|█████████▉| 2425/2437 [04:48<00:01,  8.40it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5: 100%|█████████▉| 2430/2437 [04:48<00:00,  8.42it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Validating:  98%|█████████▊| 388/395 [00:15<00:00, 29.25it/s]\u001b[A\n",
      "Epoch 5: 100%|█████████▉| 2435/2437 [04:48<00:00,  8.43it/s, loss=0.0404, v_num=6, val_loss=0.0814]\n",
      "Epoch 5: 100%|██████████| 2437/2437 [04:49<00:00,  8.43it/s, loss=0.0404, v_num=6, val_loss=0.0798]\n",
      "Epoch 6:  84%|████████▍ | 2042/2437 [06:06<01:10,  5.56it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/395 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  84%|████████▍ | 2045/2437 [06:07<01:10,  5.56it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6:  84%|████████▍ | 2050/2437 [06:08<01:09,  5.57it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:   2%|▏         | 8/395 [00:01<00:35, 10.78it/s]\u001b[A\n",
      "Epoch 6:  84%|████████▍ | 2055/2437 [06:08<01:08,  5.58it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6:  85%|████████▍ | 2060/2437 [06:08<01:07,  5.59it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6:  85%|████████▍ | 2065/2437 [06:08<01:06,  5.60it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:   6%|▌         | 23/395 [00:01<00:15, 24.15it/s]\u001b[A\n",
      "Epoch 6:  85%|████████▍ | 2070/2437 [06:08<01:05,  5.61it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6:  85%|████████▌ | 2075/2437 [06:08<01:04,  5.62it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:   8%|▊         | 33/395 [00:01<00:13, 26.81it/s]\u001b[A\n",
      "Epoch 6:  85%|████████▌ | 2080/2437 [06:09<01:03,  5.64it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  10%|▉         | 39/395 [00:02<00:12, 27.45it/s]\u001b[A\n",
      "Epoch 6:  86%|████████▌ | 2085/2437 [06:09<01:02,  5.65it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6:  86%|████████▌ | 2090/2437 [06:09<01:01,  5.66it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  12%|█▏        | 48/395 [00:02<00:12, 28.32it/s]\u001b[A\n",
      "Epoch 6:  86%|████████▌ | 2095/2437 [06:09<01:00,  5.66it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  14%|█▎        | 54/395 [00:02<00:16, 20.38it/s]\u001b[A\n",
      "Epoch 6:  86%|████████▌ | 2100/2437 [06:09<00:59,  5.68it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6:  86%|████████▋ | 2105/2437 [06:10<00:58,  5.69it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  16%|█▌        | 63/395 [00:03<00:13, 25.18it/s]\u001b[A\n",
      "Epoch 6:  87%|████████▋ | 2110/2437 [06:10<00:57,  5.70it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  17%|█▋        | 69/395 [00:03<00:11, 27.20it/s]\u001b[A\n",
      "Epoch 6:  87%|████████▋ | 2115/2437 [06:10<00:56,  5.71it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6:  87%|████████▋ | 2120/2437 [06:10<00:55,  5.72it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  20%|██        | 79/395 [00:03<00:11, 28.52it/s]\u001b[A\n",
      "Epoch 6:  87%|████████▋ | 2125/2437 [06:10<00:54,  5.73it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6:  87%|████████▋ | 2130/2437 [06:11<00:53,  5.74it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  22%|██▏       | 88/395 [00:04<00:11, 27.40it/s]\u001b[A\n",
      "Epoch 6:  88%|████████▊ | 2135/2437 [06:11<00:52,  5.75it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  24%|██▍       | 94/395 [00:04<00:10, 27.50it/s]\u001b[A\n",
      "Epoch 6:  88%|████████▊ | 2140/2437 [06:11<00:51,  5.76it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6:  88%|████████▊ | 2145/2437 [06:11<00:50,  5.77it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  26%|██▌       | 103/395 [00:04<00:17, 17.12it/s]\u001b[A\n",
      "Epoch 6:  88%|████████▊ | 2150/2437 [06:11<00:49,  5.78it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  28%|██▊       | 109/395 [00:04<00:13, 21.44it/s]\u001b[A\n",
      "Epoch 6:  88%|████████▊ | 2155/2437 [06:12<00:48,  5.79it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6:  89%|████████▊ | 2160/2437 [06:12<00:47,  5.80it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  30%|██▉       | 118/395 [00:05<00:10, 25.78it/s]\u001b[A\n",
      "Epoch 6:  89%|████████▉ | 2165/2437 [06:12<00:46,  5.81it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  31%|███▏      | 124/395 [00:05<00:09, 27.29it/s]\u001b[A\n",
      "Epoch 6:  89%|████████▉ | 2170/2437 [06:12<00:45,  5.82it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6:  89%|████████▉ | 2175/2437 [06:12<00:44,  5.83it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  34%|███▎      | 133/395 [00:05<00:09, 27.33it/s]\u001b[A\n",
      "Epoch 6:  89%|████████▉ | 2180/2437 [06:13<00:43,  5.84it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  35%|███▌      | 139/395 [00:06<00:09, 27.38it/s]\u001b[A\n",
      "Epoch 6:  90%|████████▉ | 2185/2437 [06:13<00:43,  5.85it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6:  90%|████████▉ | 2190/2437 [06:13<00:42,  5.87it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  37%|███▋      | 148/395 [00:06<00:08, 28.39it/s]\u001b[A\n",
      "Epoch 6:  90%|█████████ | 2195/2437 [06:13<00:41,  5.87it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  39%|███▉      | 154/395 [00:06<00:11, 21.30it/s]\u001b[A\n",
      "Epoch 6:  90%|█████████ | 2200/2437 [06:13<00:40,  5.88it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6:  90%|█████████ | 2205/2437 [06:14<00:39,  5.89it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  41%|████▏     | 163/395 [00:07<00:09, 25.30it/s]\u001b[A\n",
      "Epoch 6:  91%|█████████ | 2210/2437 [06:14<00:38,  5.90it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  43%|████▎     | 169/395 [00:07<00:08, 27.33it/s]\u001b[A\n",
      "Epoch 6:  91%|█████████ | 2215/2437 [06:14<00:37,  5.92it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6:  91%|█████████ | 2220/2437 [06:14<00:36,  5.93it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  45%|████▌     | 178/395 [00:07<00:07, 28.15it/s]\u001b[A\n",
      "Epoch 6:  91%|█████████▏| 2225/2437 [06:14<00:35,  5.94it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  47%|████▋     | 184/395 [00:07<00:07, 27.70it/s]\u001b[A\n",
      "Epoch 6:  92%|█████████▏| 2230/2437 [06:14<00:34,  5.95it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6:  92%|█████████▏| 2235/2437 [06:15<00:33,  5.96it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  49%|████▉     | 193/395 [00:08<00:07, 28.27it/s]\u001b[A\n",
      "Epoch 6:  92%|█████████▏| 2240/2437 [06:15<00:33,  5.97it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  50%|█████     | 199/395 [00:08<00:06, 28.43it/s]\u001b[A\n",
      "Epoch 6:  92%|█████████▏| 2245/2437 [06:15<00:32,  5.98it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6:  92%|█████████▏| 2250/2437 [06:15<00:31,  5.99it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  53%|█████▎    | 209/395 [00:08<00:07, 23.88it/s]\u001b[A\n",
      "Epoch 6:  93%|█████████▎| 2255/2437 [06:15<00:30,  6.00it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6:  93%|█████████▎| 2260/2437 [06:16<00:29,  6.01it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  55%|█████▌    | 218/395 [00:09<00:06, 26.13it/s]\u001b[A\n",
      "Epoch 6:  93%|█████████▎| 2265/2437 [06:16<00:28,  6.02it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  57%|█████▋    | 224/395 [00:09<00:06, 27.50it/s]\u001b[A\n",
      "Epoch 6:  93%|█████████▎| 2270/2437 [06:16<00:27,  6.03it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6:  93%|█████████▎| 2275/2437 [06:16<00:26,  6.04it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  59%|█████▉    | 233/395 [00:09<00:05, 28.29it/s]\u001b[A\n",
      "Epoch 6:  94%|█████████▎| 2280/2437 [06:16<00:25,  6.05it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  61%|██████    | 239/395 [00:09<00:05, 27.84it/s]\u001b[A\n",
      "Epoch 6:  94%|█████████▍| 2285/2437 [06:17<00:25,  6.06it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6:  94%|█████████▍| 2290/2437 [06:17<00:24,  6.07it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  63%|██████▎   | 248/395 [00:10<00:05, 28.65it/s]\u001b[A\n",
      "Epoch 6:  94%|█████████▍| 2295/2437 [06:17<00:23,  6.08it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  64%|██████▍   | 254/395 [00:10<00:06, 21.45it/s]\u001b[A\n",
      "Epoch 6:  94%|█████████▍| 2300/2437 [06:17<00:22,  6.09it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6:  95%|█████████▍| 2305/2437 [06:17<00:21,  6.10it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  67%|██████▋   | 263/395 [00:10<00:05, 24.12it/s]\u001b[A\n",
      "Epoch 6:  95%|█████████▍| 2310/2437 [06:18<00:20,  6.11it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  68%|██████▊   | 269/395 [00:11<00:04, 25.71it/s]\u001b[A\n",
      "Epoch 6:  95%|█████████▍| 2315/2437 [06:18<00:19,  6.12it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6:  95%|█████████▌| 2320/2437 [06:18<00:19,  6.13it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  70%|███████   | 278/395 [00:11<00:04, 27.42it/s]\u001b[A\n",
      "Epoch 6:  95%|█████████▌| 2325/2437 [06:18<00:18,  6.14it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6:  96%|█████████▌| 2330/2437 [06:18<00:17,  6.15it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  73%|███████▎  | 288/395 [00:11<00:03, 28.65it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  96%|█████████▌| 2335/2437 [06:19<00:16,  6.16it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  74%|███████▍  | 294/395 [00:12<00:03, 26.87it/s]\u001b[A\n",
      "Epoch 6:  96%|█████████▌| 2340/2437 [06:19<00:15,  6.17it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6:  96%|█████████▌| 2345/2437 [06:19<00:14,  6.18it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  77%|███████▋  | 303/395 [00:12<00:05, 17.32it/s]\u001b[A\n",
      "Epoch 6:  96%|█████████▋| 2350/2437 [06:19<00:14,  6.19it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  78%|███████▊  | 309/395 [00:12<00:04, 21.29it/s]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 2355/2437 [06:19<00:13,  6.20it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6:  97%|█████████▋| 2360/2437 [06:20<00:12,  6.21it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  81%|████████  | 319/395 [00:13<00:02, 26.14it/s]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 2365/2437 [06:20<00:11,  6.22it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6:  97%|█████████▋| 2370/2437 [06:20<00:10,  6.23it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  83%|████████▎ | 328/395 [00:13<00:02, 28.10it/s]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 2375/2437 [06:20<00:09,  6.24it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6:  98%|█████████▊| 2380/2437 [06:20<00:09,  6.25it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  86%|████████▌ | 338/395 [00:13<00:01, 29.36it/s]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 2385/2437 [06:20<00:08,  6.26it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  87%|████████▋ | 344/395 [00:13<00:01, 28.19it/s]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 2390/2437 [06:21<00:07,  6.27it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6:  98%|█████████▊| 2395/2437 [06:21<00:06,  6.28it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  89%|████████▉ | 353/395 [00:14<00:02, 18.23it/s]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 2400/2437 [06:21<00:05,  6.29it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  91%|█████████ | 359/395 [00:14<00:01, 22.40it/s]\u001b[A\n",
      "Epoch 6:  99%|█████████▊| 2405/2437 [06:21<00:05,  6.30it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6:  99%|█████████▉| 2410/2437 [06:22<00:04,  6.31it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  93%|█████████▎| 368/395 [00:15<00:01, 25.49it/s]\u001b[A\n",
      "Epoch 6:  99%|█████████▉| 2415/2437 [06:22<00:03,  6.32it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6:  99%|█████████▉| 2420/2437 [06:22<00:02,  6.33it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  96%|█████████▌| 378/395 [00:15<00:00, 27.90it/s]\u001b[A\n",
      "Epoch 6: 100%|█████████▉| 2425/2437 [06:22<00:01,  6.34it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6: 100%|█████████▉| 2430/2437 [06:22<00:01,  6.35it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Validating:  98%|█████████▊| 389/395 [00:15<00:00, 29.70it/s]\u001b[A\n",
      "Epoch 6: 100%|█████████▉| 2435/2437 [06:22<00:00,  6.36it/s, loss=0.0403, v_num=6, val_loss=0.0798]\n",
      "Epoch 6: 100%|██████████| 2437/2437 [06:23<00:00,  6.36it/s, loss=0.0403, v_num=6, val_loss=0.0794]\n",
      "Epoch 7:  60%|█████▉    | 1460/2437 [04:10<02:47,  5.84it/s, loss=0.0405, v_num=6, val_loss=0.0794]"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    gpus=1, max_epochs=20,\n",
    "    accumulate_grad_batches=32,\n",
    "    terminate_on_nan=True, \n",
    "    default_root_dir='logs/DnCNN_gaussian',\n",
    "    callbacks=[\n",
    "        pl.callbacks.ModelCheckpoint(\n",
    "            save_last=True,\n",
    "            save_top_k=4, \n",
    "            monitor='val_loss', \n",
    "            filename='{epoch}-{ssim:.4f}-{psnr:.4f}-{nmse:.5f}'\n",
    "        ),\n",
    "        pl.callbacks.LearningRateMonitor(logging_interval='epoch'),\n",
    "        pl.callbacks.GPUStatsMonitor(temperature=True)\n",
    "    ]\n",
    ");\n",
    "\n",
    "trainer.fit(net, train_dataloader=train_generator, val_dataloaders=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.net.state_dict(), 'dncnn-with-gaussian.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-effects",
   "metadata": {},
   "source": [
    "### Salt&Pepper Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-evolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.net.load_state_dict(torch.load('dncnn-noiseless.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-interpretation",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = FastMRITransform(\n",
    "    RandomMaskFunc([0.08], [4]),\n",
    "    noise_level=5e4,\n",
    "    noise_type='salt'\n",
    ")\n",
    "\n",
    "train_dataset = FastMRIh5Dataset('small_fastmri_pd_3t/train.h5', transform)\n",
    "val_dataset = FastMRIh5Dataset('small_fastmri_pd_3t/val.h5', transform)\n",
    "train_generator = torch.utils.data.DataLoader(train_dataset, batch_size=1, num_workers=12)\n",
    "val_generator = torch.utils.data.DataLoader(val_dataset, batch_size=1, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-transcription",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    gpus=1, max_epochs=20,\n",
    "    accumulate_grad_batches=32,\n",
    "    terminate_on_nan=True, \n",
    "    default_root_dir='logs/DnCNN_salt',\n",
    "    callbacks=[\n",
    "        pl.callbacks.ModelCheckpoint(\n",
    "            save_last=True,\n",
    "            save_top_k=4, \n",
    "            monitor='val_loss', \n",
    "            filename='{epoch}-{ssim:.4f}-{psnr:.4f}-{nmse:.5f}'\n",
    "        ),\n",
    "        pl.callbacks.LearningRateMonitor(logging_interval='epoch'),\n",
    "        pl.callbacks.GPUStatsMonitor(temperature=True)\n",
    "    ]\n",
    ");\n",
    "\n",
    "trainer.fit(net, train_dataloader=train_generator, val_dataloaders=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-transaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.net.state_dict(), 'dncnn-with-salt.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-suite",
   "metadata": {},
   "source": [
    "### Gaussian + Salt&Pepper Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-freedom",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.net.load_state_dict(torch.load('dncnn-noiseless.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = FastMRITransform(\n",
    "    RandomMaskFunc([0.08], [4]),\n",
    "    noise_level=5e4,\n",
    "    noise_type='salt'\n",
    ")\n",
    "\n",
    "train_dataset = FastMRIh5Dataset('small_fastmri_pd_3t/train.h5', transform)\n",
    "val_dataset = FastMRIh5Dataset('small_fastmri_pd_3t/val.h5', transform)\n",
    "train_generator = torch.utils.data.DataLoader(train_dataset, batch_size=1, num_workers=12)\n",
    "val_generator = torch.utils.data.DataLoader(val_dataset, batch_size=1, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    gpus=1, max_epochs=20,\n",
    "    accumulate_grad_batches=32,\n",
    "    terminate_on_nan=True, \n",
    "    default_root_dir='logs/DnCNN_salt',\n",
    "    callbacks=[\n",
    "        pl.callbacks.ModelCheckpoint(\n",
    "            save_last=True,\n",
    "            save_top_k=4, \n",
    "            monitor='val_loss', \n",
    "            filename='{epoch}-{ssim:.4f}-{psnr:.4f}-{nmse:.5f}'\n",
    "        ),\n",
    "        pl.callbacks.LearningRateMonitor(logging_interval='epoch'),\n",
    "        pl.callbacks.GPUStatsMonitor(temperature=True)\n",
    "    ]\n",
    ");\n",
    "\n",
    "trainer.fit(net, train_dataloader=train_generator, val_dataloaders=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-completion",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.net.state_dict(), 'dncnn-with-gaussian-salt.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch38",
   "language": "python",
   "name": "pytorch38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "seeing-ireland",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "if not Path(\"./small_fastmri_pd_3t\").is_dir():\n",
    "    !gdown --id \"1y78Ad6WwQpMGtxfEZlp97A0iV98kAiJN\"\n",
    "    !unzip -q small_fastmri_pd_3t.zip && rm small_fastmri_pd_3t.zip\n",
    "    \n",
    "if not Path(\"./dncnn-noiseless.pth\").is_file():\n",
    "    !gdown --id \"1azlqmuIkdhcsMQJL_YObF4sEe83D8J8N\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "interior-nurse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs:  3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pylab as plt\n",
    "import torch\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import Callback, ModelCheckpoint\n",
    "from k_space_reconstruction.nets.cdn_dncnn import DnCNNDCModule, CascadeModule #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "from k_space_reconstruction.datasets.fastmri import FastMRITransform, FastMRIh5Dataset, RandomMaskFunc\n",
    "from k_space_reconstruction.utils.metrics import pt_msssim, pt_ssim, ssim, nmse, psnr\n",
    "from k_space_reconstruction.utils.loss import l1_loss, compund_mssim_l1_loss\n",
    "from k_space_reconstruction.utils.kspace import spatial2kspace, kspace2spatial\n",
    "\n",
    "print('Available GPUs: ', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-violation",
   "metadata": {},
   "source": [
    "# Dataset initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baking-bumper",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to create file (unable to open file: name = 'small_fastmri_pd_3t/train.h5', errno = 17, error message = 'File exists', flags = 15, o_flags = c2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch38/lib/python3.8/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch38/lib/python3.8/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDONLY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-92f7124504c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFastMRIh5Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'small_fastmri_pd_3t/train.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFastMRIh5Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'small_fastmri_pd_3t/val.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtrain_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dl-bia-project/k_space_reconstruction/datasets/fastmri.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hf_path, transform)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT_co\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mhf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch38/lib/python3.8/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdcc_nslots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdcc_nbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdcc_w0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0m\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                                swmr=swmr)\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch38/lib/python3.8/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    202\u001b[0m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDONLY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid mode; must be one of r, r+, w, w-, x, a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to create file (unable to open file: name = 'small_fastmri_pd_3t/train.h5', errno = 17, error message = 'File exists', flags = 15, o_flags = c2)"
     ]
    }
   ],
   "source": [
    "transform = FastMRITransform(\n",
    "    RandomMaskFunc([0.08], [4]),\n",
    "    noise_level=1000,\n",
    "    noise_type='none'\n",
    ")\n",
    "\n",
    "train_dataset = FastMRIh5Dataset('small_fastmri_pd_3t/train.h5', transform)\n",
    "val_dataset = FastMRIh5Dataset('small_fastmri_pd_3t/val.h5', transform)\n",
    "train_generator = torch.utils.data.DataLoader(train_dataset, batch_size=1, num_workers=12)\n",
    "val_generator = torch.utils.data.DataLoader(val_dataset, batch_size=1, num_workers=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-character",
   "metadata": {},
   "source": [
    "# Model definition\n",
    "also, we load weight of trained unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-reflection",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = dict(\n",
    "    dncnn_chans=64, \n",
    "    dncnn_depth=12, \n",
    "    criterion=compund_mssim_l1_loss,\n",
    "    verbose_batch=50, \n",
    "    optimizer='Adam',\n",
    "    lr=1e-4,\n",
    "    lr_step_size=3,\n",
    "    lr_gamma=0.2,\n",
    "    weight_decay=0.0\n",
    ")\n",
    "\n",
    "cascade = CascadeModule(net=torch.nn.ModuleList([DnCNNDCModule(**model_kwargs).net]), **model_kwargs)\n",
    "cascade.net[0].cascade[0].load_state_dict(torch.load('dncnn-noiseless.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-halifax",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainer():\n",
    "    return pl.Trainer(\n",
    "        gpus=1, max_epochs=5,\n",
    "        accumulate_grad_batches=32,\n",
    "        terminate_on_nan=True,\n",
    "        default_root_dir='logs/CascadeDnCNN',\n",
    "        callbacks=[\n",
    "            pl.callbacks.ModelCheckpoint(\n",
    "                save_last=True,\n",
    "                save_top_k=7, \n",
    "                monitor='val_loss', \n",
    "                filename='{epoch}-{ssim:.4f}-{psnr:.4f}-{nmse:.5f}'\n",
    "            ),\n",
    "            pl.callbacks.LearningRateMonitor(logging_interval='epoch'),\n",
    "            pl.callbacks.GPUStatsMonitor(temperature=True)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patient-campus",
   "metadata": {},
   "source": [
    "# Tensorboard logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/ --port 8001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-australian",
   "metadata": {},
   "source": [
    "# Cascade trainig\n",
    "### Iterative train.\n",
    "We sequentionaly train block (DnCNN+ DC), freeze theese layers and append new block N times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_blocks = 5\n",
    "for i in range(num_blocks):\n",
    "    # Train cascade block\n",
    "    trainer = get_trainer()\n",
    "    trainer.fit(cascade, train_dataloader=train_generator, val_dataloaders=val_generator)\n",
    "    # Freeze last cascade blocks\n",
    "    for param in cascade.net.parameters():\n",
    "        param.requires_grad = False\n",
    "    # Add new block to cascade\n",
    "    if i != num_blocks - 1:\n",
    "        cascade = CascadeModule(net=cascade.net.append(DnCNNDCModule(**model_kwargs).net), **model_kwargs)\n",
    "        # Load statedict for unet in last trainable block\n",
    "        cascade.net[-1].cascade[0].load_state_dict(torch.load('dncnn-noiseless.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-input",
   "metadata": {},
   "source": [
    "# Cascade finetuning\n",
    "Train one epoch all layers in cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade = CascadeModule\\\n",
    ".load_from_checkpoint('logs/CascadeUNet/lightning_logs/version_4/checkpoints/last.ckpt', #<-----HERE!!!!!!!!!!1111\n",
    "                      net=torch.nn.ModuleList([DnCNNDCModule(**model_kwargs).net for _ in range(5)]))\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1, max_epochs=3,\n",
    "    accumulate_grad_batches=32,\n",
    "    terminate_on_nan=True,\n",
    "    default_root_dir='logs/CascadeDnCNN',\n",
    "    callbacks=[\n",
    "        pl.callbacks.ModelCheckpoint(\n",
    "            save_last=True,\n",
    "            save_top_k=7, \n",
    "            monitor='val_loss', \n",
    "            filename='{epoch}-{ssim:.4f}-{psnr:.4f}-{nmse:.5f}'\n",
    "        ),\n",
    "        pl.callbacks.LearningRateMonitor(logging_interval='epoch'),\n",
    "        pl.callbacks.GPUStatsMonitor(temperature=True)\n",
    "    ]\n",
    ")\n",
    "for param in cascade.net.parameters():\n",
    "    param.requires_grad = True\n",
    "trainer.fit(cascade, train_dataloader=train_generator, val_dataloaders=val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-links",
   "metadata": {},
   "source": [
    "# Test model\n",
    "Load best checkpoint, inference on val dataset and save predictions to .h5 file in logs directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CascadeModule\\\n",
    ".load_from_checkpoint('logs/CascadeDnCNN/lightning_logs/version_5/checkpoints/last.ckpt', \n",
    "                      net=torch.nn.ModuleList([UnetDCModule(**model_kwargs).net for _ in range(5)]))\\\n",
    ".eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-ceiling",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = get_trainer()\n",
    "trainer.test(net, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-coral",
   "metadata": {},
   "source": [
    "# Val metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_pred = h5py.File('logs/CascadeUNet/2021-05-13 20:38:03.416343.h5')\n",
    "hf_gt = h5py.File('small_fastmri_pd_3t/val.h5')\n",
    "\n",
    "ssim_vals = []\n",
    "nmse_vals = []\n",
    "psnr_vals = []\n",
    "for k in hf_pred.keys():\n",
    "    ks = hf_gt[k][:] * 1e6\n",
    "    gt = np.stack([kspace2spatial(k) for k in ks])\n",
    "    pred = hf_pred[k][:,0]\n",
    "    ssim_vals.append(ssim(gt, pred))\n",
    "    nmse_vals.append(nmse(gt, pred))\n",
    "    psnr_vals.append(psnr(gt, pred))\n",
    "ssim_vals = np.array(ssim_vals)\n",
    "nmse_vals = np.array(nmse_vals)\n",
    "psnr_vals = np.array(psnr_vals)\n",
    "\n",
    "np.mean(ssim_vals), np.mean(nmse_vals), np.mean(psnr_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-pioneer",
   "metadata": {},
   "source": [
    "# Saving Weights of the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-survivor",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.net.state_dict(), 'cascade-x5-dncnn-dc-noiseless.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-canada",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch38",
   "language": "python",
   "name": "pytorch38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
